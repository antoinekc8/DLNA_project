{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b2ea3c",
   "metadata": {},
   "source": [
    "# **Deep learning for dynamic network analysis (DLDNA)** <br> Final project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709de10",
   "metadata": {},
   "source": [
    "**Dolphins:** R. ARNAUD M. DELPLANQUE A. KARILA-COHEN A. RAMPOLDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ec909",
   "metadata": {},
   "source": [
    "Comprehensive soil classification dataset: https://www.kaggle.com/datasets/ai4a-lab/comprehensive-soil-classification-datasets/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c8307",
   "metadata": {},
   "source": [
    "### **1. Preliminnary tasks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09158bd",
   "metadata": {},
   "source": [
    "**Import of the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00968f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings to keep notebook clean\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85253879",
   "metadata": {},
   "source": [
    "**Path configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e62f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent.resolve()\n",
    "DATA_DIR= PROJECT_ROOT / \"data\"\n",
    "PARAM_FILE = PROJECT_ROOT / \"txt\" / \"parameters.txt\"\n",
    "# utils.py functions\n",
    "UTILS_DIR = PROJECT_ROOT / \"src\"\n",
    "sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "from utils import load_parameters, load_images\n",
    "from visualization import show_soil_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580dffe",
   "metadata": {},
   "source": [
    "**Choose the good torch device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c8b4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params loaded. Device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'xpu' if hasattr(torch, \"xpu\") and torch.xpu.is_available() else 'cpu'\n",
    "print(f\"Params loaded. Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887af6c8",
   "metadata": {},
   "source": [
    "**General parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ac6785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded parameters:\n",
      "  TRAIN_RATIO = 0.7\n",
      "  VAL_RATIO = 0.1\n",
      "  TEST_RATIO = 0.2\n",
      "  BATCH_SIZE = 32\n",
      "  EPOCHS = 100\n",
      "  LEARNING_RATE = 0.01\n",
      "  SEED = 42\n",
      "  SOIL_TYPES = Alluvial_Soil,Arid_Soil,Black_Soil,Laterite_Soil,Mountain_Soil,Red_Soil,Yellow_Soil\n"
     ]
    }
   ],
   "source": [
    "# Load parameters from external file\n",
    "params = load_parameters(PARAM_FILE)\n",
    "globals().update(params)\n",
    "soil_types = params[\"SOIL_TYPES\"].split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fdb1c2",
   "metadata": {},
   "source": [
    "**Seeding to ensure reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6729b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2bda4e62750>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use parameters for seed and device\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09ac6f",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365a566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alluvial_Soil: 51 images loaded\n",
      "Arid_Soil: 284 images loaded\n",
      "Black_Soil: 255 images loaded\n",
      "Laterite_Soil: 219 images loaded\n",
      "Mountain_Soil: 201 images loaded\n",
      "Red_Soil: 109 images loaded\n",
      "Yellow_Soil: 69 images loaded\n"
     ]
    }
   ],
   "source": [
    "images_dict = {}\n",
    "\n",
    "for soil in soil_types:\n",
    "    folder = DATA_DIR / \"Orignal-Dataset\" / soil\n",
    "    images_dict[soil] = load_images(folder)\n",
    "    print(f\"{soil}: {len(images_dict[soil])} images loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e06a9",
   "metadata": {},
   "source": [
    "**Display the first pictures of each type of soil**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177db2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_dict = {soil_type: [(img_bgr, filename), ...], ...}\n",
    "show_soil_grid(images_dict, n_per_type=5, tile_size=(240, 240), pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6b7c8",
   "metadata": {},
   "source": [
    "# **1. Convolutional Neural Network (CNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c82add",
   "metadata": {},
   "source": [
    "Penser à convertir les X et y en tenseur torch avant de procéder au datasplit via ``sklearn.model_selection.train_test_split`` <br>\n",
    "```X = torch.FloatTensor(X) ``` et ```y = torch.FloatTensor(y) ``` <br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddc93d",
   "metadata": {},
   "source": [
    "> Basic convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ad9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN for RGB image classification with 128x128 input.\n",
    "    Uses AdaptiveAvgPool2d -> works even if input size changes.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=7, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 128 -> 64\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # Block 2: 64 -> 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # Block 3: 32 -> 16\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)          # (B,128,16,16) if input=128x128\n",
    "        x = self.gap(x).flatten(1)    # (B,128)\n",
    "        x = self.classifier(x)        # (B,num_classes)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9836db7",
   "metadata": {},
   "source": [
    "**Test model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b0938c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn, device):\n",
    "    \"\"\"Perform final testing on the model using the held-out test set.\"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    test_loss = 0.0  # Initialize test loss\n",
    "    all_preds = []  # Store all predictions\n",
    "    all_actuals = []  # Store all actual values\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)  # Move batch to device\n",
    "            yb = yb.to(device)  # Move labels to device\n",
    "            preds = model(xb)  # Forward pass\n",
    "            test_loss += loss_fn(preds, yb).item()  # Accumulate loss\n",
    "            all_preds.append(preds)  # Store predictions\n",
    "            all_actuals.append(yb)  # Store actuals\n",
    "            \n",
    "    test_loss /= len(test_loader)  # Average loss\n",
    "    all_preds = torch.cat(all_preds)  # Concatenate all predictions\n",
    "    all_actuals = torch.cat(all_actuals)  # Concatenate all actuals\n",
    "    \n",
    "    return test_loss, all_preds, all_actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88504c80",
   "metadata": {},
   "source": [
    "**Hyperparameters tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc56a75",
   "metadata": {},
   "source": [
    "> Grid search to find the best hyperparameters (```learning_rates, hidden_sizes```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64996464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 5e-4] \n",
    "# hidden_sizes_options = [(32,16),(64,32), (128,64)]\n",
    "\n",
    "# def grid_search_hyperparameters(\n",
    "#     train_loader,\n",
    "#     val_loader,\n",
    "#     learning_rates,\n",
    "#     hidden_sizes_options,\n",
    "#     device,\n",
    "#     epochs=10,\n",
    "#     base_model=None,\n",
    "#     model_fn=None,\n",
    "#     save_path=\"best_model.pth\",\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Grid search over learning rates and hidden layer sizes.\n",
    "#     - model_fn: callable taking hidden_sizes (e.g., (h1, h2)) and returning an nn.Module (on CPU).\n",
    "#     - hidden_sizes_options: list of tuples like [(64,32), (128,64), ...]\n",
    "#     Saves the globally best model (by validation accuracy) to 'save_path'.\n",
    "#     Returns: (results_list, best_cfg_dict, best_model_loaded)\n",
    "#     \"\"\"\n",
    "#     assert model_fn is not None, \"Provide model_fn(hidden_sizes) -> nn.Module\"\n",
    "\n",
    "#     results = []  # Store all results\n",
    "#     best_val_acc = -1.0  # Track best validation accuracy\n",
    "#     best_cfg = None  # Track best configuration\n",
    "#     best_state = None  # Track best model state\n",
    "\n",
    "#     for lr in learning_rates:  # Loop over learning rates\n",
    "#         for hidden_sizes in hidden_sizes_options:  # Loop over architectures\n",
    "#             print(f\"Testing: lr={lr}, hidden_sizes={hidden_sizes}\")\n",
    "\n",
    "#             model = model_fn(hidden_sizes).to(device)  # Create model\n",
    "#             optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Create optimizer\n",
    "#             loss_fn = nn.CrossEntropyLoss()  # Define loss function\n",
    "\n",
    "#             # Train model\n",
    "#             _, _, _, train_accuracies, val_accuracies = train_with_validation(\n",
    "#                 model=model,  # Model to train\n",
    "#                 train_loader=train_loader,  # Training data\n",
    "#                 val_loader=val_loader,  # Validation data\n",
    "#                 optimizer=optimizer,  # Optimizer\n",
    "#                 loss_fn=loss_fn,  # Loss function\n",
    "#                 device=device,  # Device\n",
    "#                 epochs=epochs,  # Number of epochs\n",
    "#                 task_type='classification'  # Task type\n",
    "#             )\n",
    "\n",
    "#             cur_best_val = max(val_accuracies)  # Get best validation accuracy\n",
    "\n",
    "#             # Store results\n",
    "#             results.append({\n",
    "#                 'lr': lr,  # Learning rate\n",
    "#                 'hidden_sizes': hidden_sizes,  # Architecture\n",
    "#                 'best_val_acc': cur_best_val,  # Best validation accuracy\n",
    "#                 'final_train_acc': train_accuracies[-1],  # Final training accuracy\n",
    "#                 'final_val_acc': val_accuracies[-1]  # Final validation accuracy\n",
    "#             })\n",
    "\n",
    "#             print(f\"Best validation accuracy: {cur_best_val:.2f}%\")\n",
    "\n",
    "#             # Update best model if this is better\n",
    "#             if cur_best_val > best_val_acc:\n",
    "#                 best_val_acc = cur_best_val  # Update best accuracy\n",
    "#                 best_cfg = {'lr': lr, 'hidden_sizes': hidden_sizes}  # Update best config\n",
    "#                 best_state = {k: v.cpu() for k, v in model.state_dict().items()}  # Save state to CPU\n",
    "#                 if save_path is not None:\n",
    "#                     torch.save(best_state, save_path)  # Save to disk\n",
    "#                     print(f\"Saved new best model to: {save_path}\")\n",
    "\n",
    "#             del model  # Free memory\n",
    "#             if torch.cuda.is_available():\n",
    "#                 torch.cuda.empty_cache()  # Clear CUDA cache\n",
    "\n",
    "#     # Rebuild best model\n",
    "#     best_model = None\n",
    "#     if best_state is not None:\n",
    "#         best_model = model_fn(best_cfg['hidden_sizes']).to(device)  # Create model\n",
    "#         best_model.load_state_dict(best_state)  # Load best weights\n",
    "\n",
    "\n",
    "#     return results, best_cfg, best_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dldna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
