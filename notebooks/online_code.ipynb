{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d7391",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5053b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyaug_path = '/kaggle/input/comprehensive-soil-classification-datasets/CyAUG-Dataset'\n",
    "original_path = '/kaggle/input/comprehensive-soil-classification-datasets/Orignal-Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a83d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/keras-team/keras-preprocessing.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e3a99",
   "metadata": {},
   "source": [
    "# **Explanatory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# deep learning libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import applications\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c85f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import PIL\n",
    "from io import BytesIO\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1861a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path(\"/kaggle/input/comprehensive-soil-classification-datasets/CyAUG-Dataset\")\n",
    "\n",
    "# Find all image files recursively\n",
    "img_files = list(img_dir.rglob(\"*.jpg\"))  # or *.png, depending on your dataset\n",
    "\n",
    "# Sample and plot\n",
    "sample_images = random.sample(img_files, 6)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.parent.name)  # or use img_path.name[:20]\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/kaggle/working/sample_1.png')  # ✅ Saves to file, not notebook\n",
    "#plt.close() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d735770",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path(\"/kaggle/input/comprehensive-soil-classification-datasets/Orignal-Dataset\")\n",
    "\n",
    "# Find all image files recursively\n",
    "img_files = list(img_dir.rglob(\"*.jpg\"))  # or *.png, depending on your dataset\n",
    "\n",
    "# Sample and plot\n",
    "sample_images = random.sample(img_files, 6)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.parent.name)  # or use img_path.name[:20]\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/kaggle/working/sample_1.png')  # ✅ Saves to file, not notebook\n",
    "#plt.close() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47271cb4",
   "metadata": {},
   "source": [
    "# **Prepare the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307c53b",
   "metadata": {},
   "source": [
    "**Standardizing The Data** \n",
    "\n",
    "Our image are already in a standard size (224x224), as they are being yielded as contiguous float32 batches by our dataset. However, their RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small. Here, we will standardize values to be in the [0, 1] by using a Rescaling layer at the start of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data agumentation and pre-processing using tensorflow\n",
    "gen = ImageDataGenerator(\n",
    "                  rescale=1./255.,\n",
    "                  horizontal_flip = True,\n",
    "                  validation_split=0.2 # training: 80% data, validation: 20% data\n",
    "                 )\n",
    "\n",
    "train_generator = gen.flow_from_directory(\n",
    "    directory = cyaug_path, # images data path / folder in which images are there\n",
    "    subset=\"training\",\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (224, 224), # image height , image width\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = gen.flow_from_directory(\n",
    "    #df_val, # dataframe\n",
    "    directory = cyaug_path, # images data path / folder in which images are there\n",
    "    subset = \"validation\",\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (224, 224), # image height , image width\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2eff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(train_generator)\n",
    "x.shape # input shape of one record is (224, 224,3) , 64: is the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9d943",
   "metadata": {},
   "source": [
    "# **Plot images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_generator.class_indices\n",
    "class_names = list(a.keys())  # storing class/breed names in a list\n",
    "\n",
    "\n",
    "def plot_images(img, labels):\n",
    "    plt.figure(figsize=[15, 10])\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(img[i])\n",
    "        plt.title(class_names[np.argmax(labels[i])])\n",
    "        plt.axis('off')\n",
    "\n",
    "plot_images(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbe3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a6715",
   "metadata": {},
   "source": [
    "# **Building the CNN Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab6f00",
   "metadata": {},
   "source": [
    "We'll build a small version of the Xception network. \n",
    "\n",
    "Note that:\n",
    "\n",
    "* We start the model by a Rescaling layer.\n",
    "* We include a Dropout layer before the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x) \n",
    "x = Dropout(0.2)(x)  \n",
    "predictions = Dense(7, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ed9cd",
   "metadata": {},
   "source": [
    "# **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# categorical cross entropy is taken since its used as a loss function for \n",
    "# multi-class classification problems where there are two or more output labels.\n",
    "# using Adam optimizer for better performance\n",
    "# other optimizers such as sgd can also be used depending upon the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48060ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = tf.keras.callbacks.EarlyStopping( patience=10,\n",
    "                                          min_delta=0.001,\n",
    "                                          restore_best_weights=True)\n",
    "# early stopping call back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b927a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                    callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d714192",
   "metadata": {},
   "source": [
    "# **Run Inference On New Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e782574",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.utils.load_img(\"/kaggle/input/comprehensive-soil-classification-datasets/CyAUG-Dataset/Alluvial_Soil/103.jpg\", target_size=image_size)\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = float(keras.ops.sigmoid(predictions[0][0]))\n",
    "print(f\"This image is {100 * (1 - score):.2f}% Alluvial Soil and {100 * score:.2f}% not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd15611",
   "metadata": {},
   "source": [
    "# **Plotting The Training And Validation Accuracy And Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647cf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "# plot results\n",
    "# accuracy\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['lines.linestyle'] = '--'\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "#plt.title(f'Training and Validation Loss. \\nTrain Loss: \n",
    "         # {str(loss[-1])}\\nValidation Loss: {str(val_loss[-1])}')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e325f1f",
   "metadata": {},
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159035d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# === Evaluate with Confusion Matrix ===\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in validation_generator:\n",
    "    logits = model.predict(images)\n",
    "    preds = tf.argmax(logits, axis=1)\n",
    "    y_true.extend(labels)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))  # You can adjust size as needed\n",
    "disp.plot(ax=ax, cmap='Oranges')\n",
    "#disp.plot(xticks_rotation='vertical')\n",
    "plt.title(\"Confusion Matrix on Validation Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a23df",
   "metadata": {},
   "source": [
    "# **Evaluate Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12489850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
